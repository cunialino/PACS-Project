# NB: IC contiene lo 0! dunque, volendolo sfruttare per eseguire il test, NON ci fornisce evidenza
# per rifiutare H0: beta_pop75 = 0 ( infatti coefficiente non significativo )
# similarly for parameter of ddpi:
c( 0.41-2.01 * 0.196, 0.41 + 2.01 * 0.196 )
# NB: qui l'IC utilizzato per eseguire il test mi porterebbe a rifiutare H0: beta_ddpi = 0, dato che
# 0 non rientra tra i valori "plausibili" che avrebbero reso probabile l'osservare il campione
# effettivamente osservato.
# Notice that this confidence interval is pretty wide in the sense that the upper limit is about 50
# times larger than the lower limit.
# This means that we are not really that confident about what the exact effect of growth on savings
# really is.
# Confidence intervals often have a duality with two-sided hypothesis tests.
# A 95% confidence interval contains all the null hypotheses that would not be rejected at the 5%
# level.
# Thus the interval for pop75 contains zero which indicates that the null hypothesis
#  H0 : beta_pop75 = 0 would not be rejected at the 5% level.
# IMPORTANT REMARK:
# We can see from the output above that the p-value is 12.5% - greater than 5% - confirming this point.
# In contrast, we see that the interval for ddpi does not contain zero and so the null hypothesis is
# rejected for this regression parameter.
# Costruzione di regioni di confidenza --------------------------------------------------------
# Joint 95% confidence region for parameters pop15 e pop75.
library( ellipse )  # load the library for drawing confidence ellipses
help( ellipse )
g
dev.new()
plot( ellipse( g, c( 2, 3 ) ), type = "l", xlim = c( -1, 0 ) )
# add the origin and the point of the estimates:
# vettore che stiamo testando nell'hp nulla
points( 0, 0 )
# le stime dei 2 param sono il centro dell'ellisse
points( g$coef [ 2 ] , g$coef [ 3 ] , pch = 18 )
# NOTA: la regione di confidenza non copre il valore del vettore beta proposto dall'hp nulla
#    = > RIFIUTO H0 secondo cui entrambi sono nulli = > ALMENO UNO dei 2 coeff non è uguale a zero
# Now we mark the one way confidence intervals on the plot for reference:
abline( v = c( -0.461-2.01 * 0.145, -0.461 + 2.01 * 0.145 ), lty = 2 )
abline( h = c( -1.69-2.01 * 1.08, -1.69 + 2.01 * 1.08 ), lty = 2 )
# COMMENTO:
# Le linee tratteggiate rappresentano i test "uno alla volta" eseguiti sui singoli coeff, di livello 95%
# Il fatto che l'ellisse non copra lo zero, ci porta a rifiutare l'hp nulla che la coppia di param
# sia nulla ( e che quindi le corrispondenti variabili siano NON significative )
# L'origine cade all'interno dell'IC si pop75 e non in quello di pop15, infatti il primo non abbiamo
# motivo per ritenere che sia significativam diverso da 0, mentre il secondo si
# Ci potrebbero essere casi in cui una regione porta a rifiutare e l'altra no
points( -0.22, 0.7, col = "red", lwd = 2 )
points( -0.71, 0, col = "blue", lwd = 2 )
# quindi preferire sempre la regione congiunta, ove possibile, perché sta tenendo conto della
# correlazione tra i coeff.
# correlazione tra v.a. pop15 e pop75
cor( savings$pop15, savings$pop75 )
# Verifica delle ipotesi ----------------------------------------------------------------------
g = lm( sr ~ pop15 + pop75 + dpi + ddpi, savings )
# Verifica dell'hp di omoschedasticità dei residui
# Plot dei residui ( epsilon.hat ) vs i valori fittati ( y.hat )
plot( g$fit, g$res, xlab = "Fitted", ylab = "Residuals", main = "Residuals vs Fitted Values", pch = 16 )
abline( h = 0, lwd = 2, lty = 2, col = 'red' )  # variabilità sembra sufficientemente uniforme
# Verifica dell'eventuale presenza di nonlinearità
# Plot dei residui ( epsilon.hat ) vs i singoli predittori ( x_i )
dev.new()
par( mfrow = c( 2, 2 ) )
plot( savings$pop15, g$res, xlab = "Population under 15", ylab = "Residuals",
main = "Residuals vs pop15", pch = 16 )
plot( savings$pop75, g$res, xlab = "Population over 75", ylab = "Residuals",
main = "Residuals vs pop75", pch = 16 )
plot( savings$dpi, g$res, xlab = "dpi", ylab = "Residuals", main = "Residuals vs dpi", pch = 16 )
plot( savings$ddpi, g$res, xlab = "ddpi", ylab = "Residuals", main = "Residuals vs ddpi", pch = 16 )
# Verifica dell'hp di Normalità
dev.new()
par( mfrow = c( 2, 2 ) )
# QQ plot
qqnorm( g$res, ylab = "Raw Residuals", pch = 16 )
qqline( g$res )
# Andamento adeguatamente rettilineo, l'ipotesi è verificata
# La funzione `rstandard` calcola automaticamente i residui studentizzati,
# (mentre la funzione rstudent calcola i residui jackknife), attenzione perché i nomi sono
# contro-intuitivi!
qqnorm( rstudent( g ), ylab = "Studentized residuals", pch = 16 )
abline( 0, 1 )
# altri strumenti utili...
hist( g$res, 10, probability = TRUE, col = 'lavender', main = 'residuals'  )
boxplot( g$res, main = "Boxplot of savings residuals", pch = 16, col = 'lavender' )
# Shapiro-Wilk normality test
# p-val molto alto = > NON rifiuto H0: dati Gaussiani
shapiro.test( g$res )
# Verifica delle ipotesi ----------------------------------------------------------------------
g = lm( sr ~ pop15 + pop75 + dpi + ddpi, savings )
# Verifica dell'hp di omoschedasticità dei residui
# Plot dei residui ( epsilon.hat ) vs i valori fittati ( y.hat )
plot( g$fit, g$res, xlab = "Fitted", ylab = "Residuals", main = "Residuals vs Fitted Values", pch = 16 )
abline( h = 0, lwd = 2, lty = 2, col = 'red' )  # variabilità sembra sufficientemente uniforme
# Verifica dell'eventuale presenza di nonlinearità
# Plot dei residui ( epsilon.hat ) vs i singoli predittori ( x_i )
#dev.new()
par( mfrow = c( 2, 2 ) )
plot( savings$pop15, g$res, xlab = "Population under 15", ylab = "Residuals",
main = "Residuals vs pop15", pch = 16 )
plot( savings$pop75, g$res, xlab = "Population over 75", ylab = "Residuals",
main = "Residuals vs pop75", pch = 16 )
plot( savings$dpi, g$res, xlab = "dpi", ylab = "Residuals", main = "Residuals vs dpi", pch = 16 )
plot( savings$ddpi, g$res, xlab = "ddpi", ylab = "Residuals", main = "Residuals vs ddpi", pch = 16 )
# Verifica dell'hp di Normalità
#dev.new()
par( mfrow = c( 2, 2 ) )
# QQ plot
qqnorm( g$res, ylab = "Raw Residuals", pch = 16 )
qqline( g$res )
# Andamento adeguatamente rettilineo, l'ipotesi è verificata
# La funzione `rstandard` calcola automaticamente i residui studentizzati,
# (mentre la funzione rstudent calcola i residui jackknife), attenzione perché i nomi sono
# contro-intuitivi!
qqnorm( rstudent( g ), ylab = "Studentized residuals", pch = 16 )
abline( 0, 1 )
# altri strumenti utili...
hist( g$res, 10, probability = TRUE, col = 'lavender', main = 'residuals'  )
boxplot( g$res, main = "Boxplot of savings residuals", pch = 16, col = 'lavender' )
# Shapiro-Wilk normality test
# p-val molto alto = > NON rifiuto H0: dati Gaussiani
shapiro.test( g$res )
# Esempi di violazione dell’ipotesi di omoschedasticità ---------------------------------------
par( mfrow = c( 3, 3 ) )
# Omoschedasticità
for( i in 1:9 )
plot( 1:50, rnorm( 50 ), pch = 16 )
# Eteroschedasticità marcata (varianza funzione lineare di x)
for( i in 1:9 )
plot( 1:50, ( 1:50 ) * rnorm( 50 ), pch = 16 )
# Eteroschedasticità blanda (varianza funzione sublineare di x)
for( i in 1:9 )
plot( 1:50, sqrt( ( 1:50 ) ) * rnorm( 50 ), ylim = c( -50, 50 ), pch = 16 )
# Non linearità (varianza funzione nonlineare di x)
for( i in 1:9 )
plot( 1:50, cos( ( 1:50 ) * pi/25 ) + rnorm( 50 ), pch = 16 )
install.packages("car")
# Esempi di violazione dell’ipotesi di omoschedasticità ---------------------------------------
par( mfrow = c( 3, 3 ) )
# Omoschedasticità
for( i in 1:9 )
plot( 1:50, rnorm( 50 ), pch = 16 )
# Eteroschedasticità marcata (varianza funzione lineare di x)
for( i in 1:9 )
plot( 1:50, ( 1:50 ) * rnorm( 50 ), pch = 16 )
# Eteroschedasticità blanda (varianza funzione sublineare di x)
for( i in 1:9 )
plot( 1:50, sqrt( ( 1:50 ) ) * rnorm( 50 ), ylim = c( -50, 50 ), pch = 16 )
# Non linearità (varianza funzione nonlineare di x)
for( i in 1:9 )
plot( 1:50, cos( ( 1:50 ) * pi/25 ) + rnorm( 50 ), pch = 16 )
par( mfrow = c( 3, 3 ) )
# Normali
for( i in 1:9 )
{
D = rnorm( 50 )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
dev.new()
# Esponenziali
for( i in 1:9 )
{
D = rexp( 50 )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
dev.new()
par( mfrow = c(3,3) )
# Log-normali
for( i in 1:9 )
{
D = exp( rnorm( 50 ) )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
# Cauchy
for( i in 1:9 )
{
D = rcauchy( 50 )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
dev.new()
par( mfrow = c(3,3) )
# Uniforme
for( i in 1:9 )
{
D = runif( 50 )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
#dev.new()
par( mfrow = c( 3, 3 ) )
# Normali
for( i in 1:9 )
{
D = rnorm( 50 )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
#dev.new()
# Esponenziali
for( i in 1:9 )
{
D = rexp( 50 )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
#dev.new()
par( mfrow = c(3,3) )
# Log-normali
for( i in 1:9 )
{
D = exp( rnorm( 50 ) )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
# Cauchy
for( i in 1:9 )
{
D = rcauchy( 50 )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
#dev.new()
par( mfrow = c(3,3) )
# Uniforme
for( i in 1:9 )
{
D = runif( 50 )
qqnorm( D, pch = 16 )
qqline( D, lty = 2, lwd = 2, col = 'red' )
}
install.packages("RColorBrewer")
display.brewer.all()
library(RColorBrewer)
display.brewer.all()
install.packages("nord")
clear
clc
library(nord)
library(GWmodel)
data(LondonHP)
DM<-gw.dist(dp.locat=coordinates(londonhp))
bw<-bw.gwr(PURCHASE~FLOORSZ,data=londonhp,dMat=DM, kernel="gaussian")
#See any difference in the next two commands and why?
res.mont1<-gwr.montecarlo(PURCHASE~PROF+FLOORSZ, data = londonhp,dMat=DM, nsim=99, kernel="gaussian", adaptive=FALSE, bw = bw)
max(DM)
bw<-bw.gwr(PURCHASE~FLOORSZ + PROF,data=londonhp,dMat=DM, kernel="gaussian")
library(GWmodel)
data(LondonHP)
DM<-gw.dist(dp.locat=coordinates(londonhp))
DM[2]
DM
library(GWmodel)
data(LondonHP)
DM<-gw.dist(dp.locat=coordinates(londonhp))
bw<-bw.gwr(PURCHASE~ FLOORSZ + PROF,data=londonhp,dMat=DM, kernel="gaussian")
library(GWmodel)
data(LondonHP)
DM<-gw.dist(dp.locat=coordinates(londonhp))
bw<-bw.gwr(PURCHASE~ FLOORSZ + PROF,data=londonhp,dMat=DM, kernel="gaussian")
bw<-bw.gwr(PURCHASE~ FLOORSZ + PROF,data=londonhp,dMat=DM, kernel="gaussian", adaptive = FALSE)
bw<-bw.gwr(PURCHASE~ FLOORSZ + PROF,data=londonhp,dMat=DM, kernel="gaussian", adaptive = FALSE)
#See any difference in the next two commands and why?
res.mont1<-gwr.montecarlo(PURCHASE~PROF+FLOORSZ, data = londonhp,dMat=DM, nsim=99, kernel="gaussian", adaptive=FALSE, bw = bw)
#See any difference in the next two commands and why?
res.mont1<-gwr.montecarlo(PURCHASE~PROF+FLOORSZ, data = londonhp,dMat=DM, nsim=99, kernel="gaussian", adaptive=FALSE, bw = bw)
#See any difference in the next two commands and why?
res.mont1<-gwr.montecarlo(PURCHASE~PROF+FLOORSZ, data = londonhp,dMat=DM, nsim=99, kernel="gaussian", adaptive=FALSE, bw = bw)
#See any difference in the next two commands and why?
res.mont1<-gwr.montecarlo(PURCHASE~PROF+FLOORSZ, data = londonhp,dMat=DM, nsim=99, kernel="gaussian", adaptive=FALSE, bw = bw)
tt = c(50, 122, 53, 118, 54, 128, 55, 121, 56, 125, 59, 136, 62, 144, 65, 142, 67, 149, 71, 161, 72, 167, 74, 168, 75, 162, 76, 171, 79, 175, 80, 182, 82, 180, 85, 183, 87, 188 ,90, 200, 93, 194, 94, 206, 95, 207, 97, 210, 100, 219)
x = c[seq(1, length((tt), 2))]
x = c[seq(1, length(tt), 2))]
x = c[seq(1, length(tt), 2)]
x = tt[seq(1, length(tt), 2)]
y = tt[seq(2, length(tt), 2)]
length(x)
length(y)
mod = lm(y~x)
summary(mod)
library(GWmodel)
data(LondonHP)
DM<-gw.dist(dp.locat=coordinates(londonhp))
bw<-bw.gwr(PURCHASE~ FLOORSZ + PROF,data=londonhp,dMat=DM, kernel="gaussian")
install.packages("nord")
data(LondonHP)
library(GWmodel)
data(LondonHP)
install.packages("spatialreg")
library(GWmodel)
install.packages("spatialreg")
install.packages("spatialreg")
install.packages("spatialreg")
library(GWmodel)
data(LondonHP)
DM<-gw.dist(dp.locat=coordinates(londonhp))
bw<-bw.gwr(PURCHASE~FLOORSZ,data=londonhp,dMat=DM, kernel="gaussian")
View(londonhp)
DM<-gw.dist(dp.locat=coordinates(londonhp), longlat = TRUE)
bw<-bw.gwr(PURCHASE~FLOORSZ,data=londonhp,dMat=DM, kernel="gaussian")
DM<-gw.dist(dp.locat=coordinates(londonhp))
bw<-bw.gwr(PURCHASE~FLOORSZ,data=londonhp,dMat=DM, kernel="gaussian")
DM<-gw.dist(dp.locat=coordinates(londonhp), longlat = TRUE)
bw<-bw.gwr(PURCHASE~FLOORSZ,data=londonhp,dMat=DM, kernel="gaussian")
DM<-gw.dist(dp.locat=coordinates(londonhp), longlat = TRUE)
bw<-bw.gwr(PURCHASE~FLOORSZ,data=londonhp,dMat=DM, kernel="gaussian")
install.packages(c("geoR", "gstat"))
library(sp)           ## Data management
library(lattice)      ## Data management
library(geoR)         ## Geostatistics
library(gstat)        ## Geostatistics
## Functions for graphics
v.f <- function(x, ...){100-cov.spatial(x, ...)}
v.f.est<-function(x,C0, ...){C0-cov.spatial(x, ...)}
data(meuse)
## Define the sample coordinates
coordinates(meuse) <- c('x','y')
# bubble plot(obj,zcol,...)
# key.space=location of the key
bubble(meuse,'zinc',do.log=TRUE,key.space='bottom')
dev.off()
# river meuse
data(meuse.riv)
meuse.lst <- list(Polygons(list(Polygon(meuse.riv)), "meuse.riv"))
meuse.sr <- SpatialPolygons(meuse.lst)
# grid for prediction
data(meuse.grid)
is(meuse.grid)
coordinates(meuse.grid) <- c('x','y')
meuse.grid <- as(meuse.grid, 'SpatialPixelsDataFrame')
image(meuse.grid, col = "lightgrey")
plot(meuse.sr, col = "grey", add = TRUE)
plot(meuse, add = TRUE)
title('meuse river geostatistical data')
dev.off()
# histogram of zinc variable
hist(meuse$zinc, breaks=16, col="grey", main='Histogram of Zn', prob = TRUE, xlab = 'Zn')
dev.off()
hist(log(meuse$zinc), breaks=16, col="grey", main='Histogram of log(Zn)', prob = TRUE, xlab = 'log(Zn)')
dev.off()
# scatterplot of log(zinc) with respect to distance from the river
xyplot(log(zinc) ~ sqrt(dist), as.data.frame(meuse))
# Negative correlation: lower distance from the river => higher level of zinc
dev.off()
# sample variogram (binned estimator)
svgm <- variogram(log(zinc) ~ 1, meuse)
plot(svgm, main = 'Sample Variogram',pch=19)
dev.off()
# the following
plot(variogram(log(zinc) ~ 1, meuse),pch=19)
dev.off()
plot(variogram(log(zinc) ~ 1, meuse, cutoff = 1000, width = 1000/15),pch=19)
dev.off()
# intervals can have different widths: to fix varying widths use the argument
# boudaries
plot(variogram(log(zinc) ~ 1, meuse, boundaries = c(0,200,seq(400,1500,100))),pch=19)
dev.off()
# list of parametric isotropic variogram models
vgm()
# some examples...
vgm(1, "Sph", 300)
vgm(1, "Sph", 300, 0.5)
# one can also add two or more models
v1 <- vgm(1, "Sph", 300, 0.5)
v2 <- vgm(0.8, "Sph", 800, add.to = v1)
v2
# this is only measurement error
vgm(0.5, "Nug", 0)
v <- variogram(log(zinc) ~ 1, meuse)
plot(v,pch=19)
dev.off()
# try reasonable initial values
fit.variogram(v, vgm(1, "Sph", 800, 1))
# try unreasonable initial values
fit.variogram(v, vgm(1, "Sph", 10, 1))
# plot of the final fit
v <- variogram(log(zinc) ~ 1, meuse)
v.fit <- fit.variogram(v, vgm(1, "Sph", 800, 1))
plot(v, v.fit, pch = 19)
# fitting method: non linear regression with minimization of weighted
# sum of squares error. final value of the minimum
attr(v.fit, 'SSErr')
# ex: fix the nugget variance to the value 0.06
fit.variogram(v, vgm(1, "Sph", 800, 0.06), fit.sills = c(FALSE, TRUE))
fit.variogram.reml(log(zinc)~1, meuse, model=vgm(0.6, "Sph", 800, 0.06))
v.fit
v.dir <- variogram(log(zinc)~1,meuse,alpha=(0:3)*45)
v.anis <- vgm(.6, "Sph", 1600, .05, anis=c(45, 0.3))
print(plot(v.dir, v.anis, pch=19))
dev.off()
print(plot(v.dir, v.anis, pch=19))
install.packages("devtools")
Hazard = la[1]*(x < pi[1]) + la[2]*(pi[1] <= x & x < pi[2]) + la[2]*(x >= pi[2])
pi = c(7, 13)
la = c(0.15, 0.1, 0.2)
x=seq(0, 20, by = .01)
Surv = exp(-Hazard * x)
Hazard = la[1]*(x < pi[1]) + la[2]*(pi[1] <= x & x < pi[2]) + la[2]*(x >= pi[2])
Surv = exp(-Hazard * x)
plot(x, Hazard, type = "l", ylim = c(0, 1))
plot(x, Survival, type = "l", ylim = c(0, 1))
Survival = exp(-Hazard * x)
plot(x, Survival, type = "l", ylim = c(0, 1))
Hazard = la[1]*(x < pi[1]) + la[2]*(pi[1] <= x & x < pi[2]) + la[3]*(x >= pi[2])
Survival = exp(-Hazard * x)
plot(x, Survival, type = "l", ylim = c(0, 1))
Hazard = la[1]*(x < pi[1]) + la[2]*(pi[1] <= x & x < pi[2]) + la[3]*(x >= pi[2])
plot(x, Hazard, type = "l", ylim = c(0, 1))
plot(x, Survival, type = "l", ylim = c(0, 1))
ifelse(x < pi[1], x, 1)
c(1, 1, 1) +1
Survival = exp(-(Hazard*x + la[1]*pi[1]*(x >= pi[1]) la[2]*pi[2]*)x >= pi[2])
Survival = exp(-(Hazard*x + la[1]*pi[1]*(x >= pi[1]) la[2]*pi[2]*)x >= pi[2]))
Survival = exp(-(Hazard*x + la[1]*pi[1]*(x >= pi[1]) + la[2]*pi[2]*)x >= pi[2]))
Survival = exp(-(Hazard*x + la[1]*pi[1]*(x >= pi[1]) + la[2]*pi[2]*(x >= pi[2]))
a
help("exp")
Survival = exp( -(Hazard*x + la[1]*pi[1]*(x >= pi[1]) + la[2]*pi[2]*(x >= pi[2])))
plot(x, Survival, type = "l", ylim = c(0, 1))
Survival = exp( -(Hazard*x + la[1]*pi[1]*(x >= pi[1]) + la[2]*(pi[2].pi[1])*(x >= pi[2])))
Survival = exp( -(Hazard*x + la[1]*pi[1]*(x >= pi[1]) + la[2]*(pi[2] - pi[1])*(x >= pi[2])))
plot(x, Survival, type = "l", ylim = c(0, 1))
plot(x, Survival, type = "l", ylim = c(0, 1))
i1 = which(x < pi[1])
i2 = which(x>=p[1] & x < pi[2])
i2 = which(x>= pi[2])
i2 = which(x>=p[1] & x < pi[2])
i3 = which(x>= pi[2])
x_shift = x
x_shift[i2] = x[i2] - pi[1]
x_shift[i3] = x[i3] - pi[2]
Survival = exp( -(Hazard*x_shift + la[1]*pi[1]*(x >= pi[1]) + la[2]*(pi[2] - pi[1])*(x >= pi[2])))
plot(x, Survival, type = "l", ylim = c(0, 1))
i2 = which(x>=p[1] & x < pi[2])
i3 = which(x>= pi[2])
i2 = which(x>=pi[1] & x < pi[2])
x_shift[i2] = x[i2] - pi[1]
x_shift[i3] = x[i3] - pi[2]
Survival = exp( -(Hazard*x_shift + la[1]*pi[1]*(x >= pi[1]) + la[2]*(pi[2] - pi[1])*(x >= pi[2])))
plot(x, Survival, type = "l", ylim = c(0, 1))
plot(x, Hazard, type = "l", ylim = c(0, 1))
Density[i1] = la[1]*Density[i1]
Density = Survival
Density[i1] = la[1]*Density[i1]
Density[i2] = la[2]*Density[i2]
Density[i3] = la[3]*Density[i3]
plot(x, Density, type = "l", ylim = c(0, 1))
plot(x, Density, type = "l")
plot(x, Hazard, type = "l", ylim = c(0, 1), cex.lab = 40)
plot(x, Hazard, type = "l", ylim = c(0, 1), cex.lab = 20)
plot(x, Hazard, type = "l", ylim = c(0, 1), cex.lab = 10)
plot(x, Hazard, type = "l", ylim = c(0, 1), cex.lab = 10pt)
plot(x, Density, type = "l", cex.lab = 1.5)
plot(x, Density, type = "l", cex.lab = 2)
plot(x, Density, type = "l", cex.lab = 4)
plot(x, Density, type = "l", main="Density", cex.main = 4)
plot(x, Survival, type = "l", main="Survival", ylim = c(0, 1), cex.main = 4)
plot(x, Hazard, type = "l", main = "Hazard", ylim = c(0, 1), cex.main = 4)
censdat = data.fram(left = c(11, 12, 15, 33, 45, 28, 16, 17, 19, 30), right = c(11, 12, 15, NA, 45, NA, NA, NA, NA, NA))
censdat = data.frame(left = c(11, 12, 15, 33, 45, 28, 16, 17, 19, 30), right = c(11, 12, 15, NA, 45, NA, NA, NA, NA, NA))
library(fitdistrplus)
fitdistcens(censdata = censdat, "weibull")
1/1.89
1/40.2
library(fitdistrplus)
censdat = data.frame(left = c(11, 12, 15, 33, 45, 28, 16, 17, 19, 30), right = c(11, 12, 15, NA, 45, NA, NA, NA, NA, NA))
fitdistcens(censdata = censdat, "weibull")
exp(-0.4622766)
exp(-0.160256)
install.packages("rms")
install.packages("Hmisc")
install.packages(c("broom", "devtools", "GWmodel", "haven", "Hmisc", "htmlTable", "knitr", "modelr", "nord", "openxlsx", "rgl", "selectr", "shiny", "spatialreg", "tidyverse", "webshot"))
install.packages(c("broom", "devtools", "GWmodel", "haven", "Hmisc", "htmlTable", "knitr", "modelr", "nord", "openxlsx", "rgl", "selectr", "shiny", "spatialreg", "tidyverse", "webshot"))
install.packages("Hmisc")
cls
setwd("~/Università/PACS/PACS-Project/data")
dat = read.csv("xor.csv", sep=",")
plot(dat$X0.860524669196376, dat$)
dat = read.csv("xor.csv", sep=",", header = FALSE)
dat
plot(dat$V1, dat$V2, col = dat$V3)
dat$V1
plot(dat$V1, dat$V2, col = dat$V3dat)
dat = read.csv("mydata.csv", sep=",", header = FALSE)
plot(dat$V1, dat$V2, col = dat$V3dat)
plot(dat$V1, dat$V2, col = dat$V3)
dat[, which(dat$V3 == 1)]
dat[which(dat$V3 == 1), ]
plot(dat$V1, dat$V2)
palette()
plot(dat$V1, dat$V2, col = as.factor(dat$V3))
hline
abline(h=0)
abline(v=0)
plot(dat$V1, dat$V2, col = as.factor(dat$V3), xlab = "X", ylab = "Y", title = "Dataset")
plot(dat$V1, dat$V2, col = as.factor(dat$V3), xlab = "X", ylab = "Y", title("Dataset"))
legend(7,4.3,unique(das.factor(dat$V3),col=1:length(as.factor(dat$V3)),pch=1)
)
legend(7,4.3,unique(as.factor(dat$V3)),col=1:length(as.factor(dat$V3)),pch=1)
legend(7,4.3,unique(as.factor(dat$V3)),col=1:length(as.factor(dat$V3)),pch=1)
clear
clc
dat=read.csv(file = "xor.csv", header = FALSE)
colnames(dat) <- c("X", "Y", "GROUP")
dat$V3 = as.factor(dat$V3)
dat$GROUP = as.factor(dat$GROUP)
dat=read.csv(file = "xor.csv", header = FALSE)
colnames(dat) <- c("X", "Y", "GROUP")
dat$GROUP = as.factor(dat$GROUP)
plot(dat$X, dat$Y, col = dat$GROUP)
plot(dat$X, dat$Y, col = dat$GROUP, xlab = "X", ylab = "Y", title("Dataset"))
abline(h=0)
abline(v=0)
